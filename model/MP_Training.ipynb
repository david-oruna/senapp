{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ad053756-515c-46d2-9b6a-83290680423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import mediapipe as mp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e743b4f-2ecd-430f-8db6-8a78e083d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Hands setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "DATA_PATH = os.path.join('abc')\n",
    "sequence_length = 30\n",
    "actions = np.array(['A','B','C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cfecd506-4efc-4ec3-82af-b0a2c73b4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    landmarks_sequence = []\n",
    "    \n",
    "    while len(landmarks_sequence) < sequence_length:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            landmarks = [[lm.x, lm.y] for lm in hand_landmarks.landmark]\n",
    "            landmarks_flattened = [coord for landmark in landmarks for coord in landmark]\n",
    "            landmarks_sequence.append(landmarks_flattened)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Pad the sequence if it's shorter than sequence_length\n",
    "    while len(landmarks_sequence) < sequence_length:\n",
    "        landmarks_sequence.append([0] * (21 * 2))  # 21 landmarks, x and y for each\n",
    "    \n",
    "    return landmarks_sequence[:sequence_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "577d4e48-49c9-412c-a8c2-3a1d9e57e8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 42)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(extract_landmarks('abc/A/10800A0911.mp4')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe45383e-52eb-4fdb-8bfe-7728ddf01e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHO_d\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (53, 30, 42)\n",
      "Testing data shape: (3, 30, 42)\n",
      "Data processing completed and saved.\n"
     ]
    }
   ],
   "source": [
    "# Collect data\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    \n",
    "    # Get all video files in the action folder\n",
    "    video_files = [f for f in os.listdir(action_path) if f.endswith(('.mp4', '.avi', '.MOV'))]\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(action_path, video_file)\n",
    "        window = extract_landmarks(video_path)\n",
    "        sequences.append(window)\n",
    "        labels.append(actions.tolist().index(action))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Save the processed data\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)\n",
    "\n",
    "print(\"Data processing completed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2b8efd3-1f76-4e46-8bbb-e8ca95acc2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions=np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'ADIOS',\n",
    "       'B', 'C', 'D', 'DISCULPA', 'E', 'F', 'G', 'GRACIAS', 'H',\n",
    "       'HERMANA', 'HOLA', 'I', 'J', 'K', 'L', 'LL', 'M', 'MAMA', 'N',\n",
    "       'NN', 'O', 'P', 'PAPA', 'PORFAVOR', 'Q', 'R', 'S', 'T', 'U', 'V',\n",
    "       'W', 'X', 'Y', 'Z'])\n",
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55c348b6-33bf-49a8-90ec-6b344a4e1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('X_test.npy')\n",
    "X_train = np.load('X_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "y_train = np.load('y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2fec8409-c76a-467e-90bb-c0e21932c7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHO_d\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build and train LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,42)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "model.load_weights('hand_action (1).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c16ca2a0-7d3a-47cb-bd70-c7970b7e9cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - categorical_accuracy: 0.8109 - loss: 0.4901\n",
      "Epoch 2/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8577 - loss: 0.3064\n",
      "Epoch 3/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8587 - loss: 0.3099\n",
      "Epoch 4/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8207 - loss: 0.4859\n",
      "Epoch 5/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8440 - loss: 0.3386\n",
      "Epoch 6/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8711 - loss: 0.2655\n",
      "Epoch 7/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8731 - loss: 0.2856\n",
      "Epoch 8/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8347 - loss: 0.4189\n",
      "Epoch 9/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8363 - loss: 0.3600\n",
      "Epoch 10/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8997 - loss: 0.2235\n",
      "Epoch 11/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8628 - loss: 0.2670\n",
      "Epoch 12/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8906 - loss: 0.2855\n",
      "Epoch 13/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - categorical_accuracy: 0.8677 - loss: 0.2700\n",
      "Epoch 14/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8354 - loss: 0.5167\n",
      "Epoch 15/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.7610 - loss: 0.6637\n",
      "Epoch 16/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.7985 - loss: 0.4497\n",
      "Epoch 17/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8755 - loss: 0.2854\n",
      "Epoch 18/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - categorical_accuracy: 0.8760 - loss: 0.2362\n",
      "Epoch 19/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - categorical_accuracy: 0.8667 - loss: 0.2795\n",
      "Epoch 20/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8664 - loss: 0.2584\n",
      "Epoch 21/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8603 - loss: 0.2751\n",
      "Epoch 22/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8773 - loss: 0.2473\n",
      "Epoch 23/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8765 - loss: 0.2461\n",
      "Epoch 24/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8524 - loss: 0.2677\n",
      "Epoch 25/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8642 - loss: 0.2408\n",
      "Epoch 26/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8783 - loss: 0.2180\n",
      "Epoch 27/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8628 - loss: 0.2953\n",
      "Epoch 28/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8726 - loss: 0.2886\n",
      "Epoch 29/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8849 - loss: 0.2354\n",
      "Epoch 30/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8912 - loss: 0.1952\n",
      "Epoch 31/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8918 - loss: 0.1894\n",
      "Epoch 32/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8819 - loss: 0.2100\n",
      "Epoch 33/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - categorical_accuracy: 0.8815 - loss: 0.2346\n",
      "Epoch 34/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8792 - loss: 0.2432\n",
      "Epoch 35/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8775 - loss: 0.2674\n",
      "Epoch 36/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8885 - loss: 0.1985\n",
      "Epoch 37/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8695 - loss: 0.2306\n",
      "Epoch 38/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8641 - loss: 0.2701\n",
      "Epoch 39/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - categorical_accuracy: 0.8920 - loss: 0.2098\n",
      "Epoch 40/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8624 - loss: 0.2565\n",
      "Epoch 41/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8924 - loss: 0.1977\n",
      "Epoch 42/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8505 - loss: 0.3323\n",
      "Epoch 43/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8080 - loss: 0.4812\n",
      "Epoch 44/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8775 - loss: 0.2526\n",
      "Epoch 45/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8883 - loss: 0.2090\n",
      "Epoch 46/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8859 - loss: 0.1990\n",
      "Epoch 47/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8840 - loss: 0.2100\n",
      "Epoch 48/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8970 - loss: 0.1824\n",
      "Epoch 49/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8740 - loss: 0.1883\n",
      "Epoch 50/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8773 - loss: 0.2198\n",
      "Epoch 51/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8708 - loss: 0.2435\n",
      "Epoch 52/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8758 - loss: 0.2652\n",
      "Epoch 53/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8751 - loss: 0.2271\n",
      "Epoch 54/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8807 - loss: 0.2177\n",
      "Epoch 55/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8926 - loss: 0.1874\n",
      "Epoch 56/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8816 - loss: 0.2249\n",
      "Epoch 57/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8742 - loss: 0.2504\n",
      "Epoch 58/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8453 - loss: 0.3317\n",
      "Epoch 59/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.7335 - loss: 0.7977\n",
      "Epoch 60/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8738 - loss: 0.2449\n",
      "Epoch 61/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8971 - loss: 0.1924\n",
      "Epoch 62/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8965 - loss: 0.1817\n",
      "Epoch 63/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8960 - loss: 0.1790\n",
      "Epoch 64/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8960 - loss: 0.1774\n",
      "Epoch 65/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.9015 - loss: 0.1870\n",
      "Epoch 66/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8857 - loss: 0.1860\n",
      "Epoch 67/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8922 - loss: 0.1937\n",
      "Epoch 68/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9030 - loss: 0.1874\n",
      "Epoch 69/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8800 - loss: 0.1882\n",
      "Epoch 70/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - categorical_accuracy: 0.8913 - loss: 0.1872\n",
      "Epoch 71/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8467 - loss: 0.3942\n",
      "Epoch 72/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8728 - loss: 0.2467\n",
      "Epoch 73/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8976 - loss: 0.1903\n",
      "Epoch 74/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - categorical_accuracy: 0.8937 - loss: 0.1920\n",
      "Epoch 75/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8795 - loss: 0.1918\n",
      "Epoch 76/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.9023 - loss: 0.1654\n",
      "Epoch 77/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8899 - loss: 0.1653\n",
      "Epoch 78/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.9034 - loss: 0.1586\n",
      "Epoch 79/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - categorical_accuracy: 0.9135 - loss: 0.1523\n",
      "Epoch 80/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8928 - loss: 0.1820\n",
      "Epoch 81/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8912 - loss: 0.1866\n",
      "Epoch 82/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - categorical_accuracy: 0.8758 - loss: 0.1883\n",
      "Epoch 83/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8978 - loss: 0.1962\n",
      "Epoch 84/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8767 - loss: 0.2841\n",
      "Epoch 85/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - categorical_accuracy: 0.8206 - loss: 0.4224\n",
      "Epoch 86/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8377 - loss: 0.4616\n",
      "Epoch 87/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8350 - loss: 0.4157\n",
      "Epoch 88/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8863 - loss: 0.2464\n",
      "Epoch 89/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8688 - loss: 0.2545\n",
      "Epoch 90/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8807 - loss: 0.2210\n",
      "Epoch 91/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8861 - loss: 0.1757\n",
      "Epoch 92/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8784 - loss: 0.1854\n",
      "Epoch 93/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8893 - loss: 0.1938\n",
      "Epoch 94/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8928 - loss: 0.1829\n",
      "Epoch 95/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.9052 - loss: 0.1617\n",
      "Epoch 96/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.9069 - loss: 0.1719\n",
      "Epoch 97/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8874 - loss: 0.2136\n",
      "Epoch 98/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8121 - loss: 0.4902\n",
      "Epoch 99/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8742 - loss: 0.2585\n",
      "Epoch 100/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8720 - loss: 0.2751\n",
      "Epoch 101/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8692 - loss: 0.3126\n",
      "Epoch 102/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - categorical_accuracy: 0.8822 - loss: 0.2300\n",
      "Epoch 103/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.9053 - loss: 0.1644\n",
      "Epoch 104/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8864 - loss: 0.1930\n",
      "Epoch 105/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8807 - loss: 0.1981\n",
      "Epoch 106/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - categorical_accuracy: 0.9006 - loss: 0.1786\n",
      "Epoch 107/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8920 - loss: 0.1807\n",
      "Epoch 108/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8983 - loss: 0.1753\n",
      "Epoch 109/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8861 - loss: 0.2076\n",
      "Epoch 110/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - categorical_accuracy: 0.8871 - loss: 0.2113\n",
      "Epoch 111/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8887 - loss: 0.2310\n",
      "Epoch 112/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8750 - loss: 0.2293\n",
      "Epoch 113/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8863 - loss: 0.1952\n",
      "Epoch 114/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9010 - loss: 0.1793\n",
      "Epoch 115/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8444 - loss: 0.3615\n",
      "Epoch 116/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8521 - loss: 0.3426\n",
      "Epoch 117/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8930 - loss: 0.1914\n",
      "Epoch 118/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - categorical_accuracy: 0.9117 - loss: 0.1548\n",
      "Epoch 119/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.9033 - loss: 0.1583\n",
      "Epoch 120/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8879 - loss: 0.1813\n",
      "Epoch 121/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8992 - loss: 0.1681\n",
      "Epoch 122/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.9045 - loss: 0.1627\n",
      "Epoch 123/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8850 - loss: 0.1635\n",
      "Epoch 124/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8909 - loss: 0.1717\n",
      "Epoch 125/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - categorical_accuracy: 0.8902 - loss: 0.1790\n",
      "Epoch 126/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.9046 - loss: 0.1655\n",
      "Epoch 127/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8941 - loss: 0.1750\n",
      "Epoch 128/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8950 - loss: 0.1706\n",
      "Epoch 129/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8880 - loss: 0.2313\n",
      "Epoch 130/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8060 - loss: 0.4589\n",
      "Epoch 131/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - categorical_accuracy: 0.8959 - loss: 0.2427\n",
      "Epoch 132/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - categorical_accuracy: 0.8798 - loss: 0.2528\n",
      "Epoch 133/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8711 - loss: 0.2692\n",
      "Epoch 134/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8939 - loss: 0.1951\n",
      "Epoch 135/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.6903 - loss: 1.1225\n",
      "Epoch 136/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8446 - loss: 0.4014\n",
      "Epoch 137/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - categorical_accuracy: 0.8856 - loss: 0.2321\n",
      "Epoch 138/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8934 - loss: 0.2027\n",
      "Epoch 139/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8853 - loss: 0.1888\n",
      "Epoch 140/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8925 - loss: 0.1952\n",
      "Epoch 141/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - categorical_accuracy: 0.8991 - loss: 0.1668\n",
      "Epoch 142/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8914 - loss: 0.1864\n",
      "Epoch 143/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8765 - loss: 0.1927\n",
      "Epoch 144/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.9047 - loss: 0.1734\n",
      "Epoch 145/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.8974 - loss: 0.1834\n",
      "Epoch 146/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8204 - loss: 0.4409\n",
      "Epoch 147/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8751 - loss: 0.2452\n",
      "Epoch 148/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - categorical_accuracy: 0.8780 - loss: 0.3140\n",
      "Epoch 149/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - categorical_accuracy: 0.8767 - loss: 0.2388\n",
      "Epoch 150/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - categorical_accuracy: 0.8989 - loss: 0.1892\n",
      "Epoch 151/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8978 - loss: 0.1720\n",
      "Epoch 152/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - categorical_accuracy: 0.9049 - loss: 0.1633\n",
      "Epoch 153/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8945 - loss: 0.1709\n",
      "Epoch 154/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8949 - loss: 0.1766\n",
      "Epoch 155/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.9071 - loss: 0.1636\n",
      "Epoch 156/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.9027 - loss: 0.1541\n",
      "Epoch 157/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8843 - loss: 0.1727\n",
      "Epoch 158/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8981 - loss: 0.1656\n",
      "Epoch 159/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.9099 - loss: 0.1592\n",
      "Epoch 160/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - categorical_accuracy: 0.9009 - loss: 0.1682\n",
      "Epoch 161/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8999 - loss: 0.1731\n",
      "Epoch 162/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.9045 - loss: 0.1606\n",
      "Epoch 163/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8895 - loss: 0.1707\n",
      "Epoch 164/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9085 - loss: 0.1513\n",
      "Epoch 165/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8738 - loss: 0.2189\n",
      "Epoch 166/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8959 - loss: 0.2081\n",
      "Epoch 167/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.7607 - loss: 0.7927\n",
      "Epoch 168/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - categorical_accuracy: 0.8199 - loss: 0.4160\n",
      "Epoch 169/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8772 - loss: 0.2154\n",
      "Epoch 170/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9106 - loss: 0.1616\n",
      "Epoch 171/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8654 - loss: 0.2063\n",
      "Epoch 172/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8929 - loss: 0.1874\n",
      "Epoch 173/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.9027 - loss: 0.1778\n",
      "Epoch 174/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8747 - loss: 0.2478\n",
      "Epoch 175/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8773 - loss: 0.2605\n",
      "Epoch 176/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8230 - loss: 0.3872\n",
      "Epoch 177/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8794 - loss: 0.2216\n",
      "Epoch 178/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.8916 - loss: 0.1878\n",
      "Epoch 179/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8771 - loss: 0.2081\n",
      "Epoch 180/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.9109 - loss: 0.1704\n",
      "Epoch 181/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - categorical_accuracy: 0.8814 - loss: 0.2009\n",
      "Epoch 182/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - categorical_accuracy: 0.9094 - loss: 0.1612\n",
      "Epoch 183/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - categorical_accuracy: 0.9105 - loss: 0.1631\n",
      "Epoch 184/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - categorical_accuracy: 0.8905 - loss: 0.1699\n",
      "Epoch 185/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - categorical_accuracy: 0.8787 - loss: 0.2304\n",
      "Epoch 186/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8987 - loss: 0.1900\n",
      "Epoch 187/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.9016 - loss: 0.1955\n",
      "Epoch 188/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - categorical_accuracy: 0.8768 - loss: 0.2255\n",
      "Epoch 189/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - categorical_accuracy: 0.8598 - loss: 0.2829\n",
      "Epoch 190/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - categorical_accuracy: 0.8581 - loss: 0.3127\n",
      "Epoch 191/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8998 - loss: 0.1915\n",
      "Epoch 192/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - categorical_accuracy: 0.8968 - loss: 0.1752\n",
      "Epoch 193/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - categorical_accuracy: 0.9223 - loss: 0.1497\n",
      "Epoch 194/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - categorical_accuracy: 0.9080 - loss: 0.1648\n",
      "Epoch 195/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8893 - loss: 0.1632\n",
      "Epoch 196/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.8995 - loss: 0.1731\n",
      "Epoch 197/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - categorical_accuracy: 0.8883 - loss: 0.1743\n",
      "Epoch 198/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9060 - loss: 0.1671\n",
      "Epoch 199/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - categorical_accuracy: 0.9125 - loss: 0.1681\n",
      "Epoch 200/200\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - categorical_accuracy: 0.9127 - loss: 0.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.fit(X_train, y_train, epochs=200, callbacks=[TensorBoard(log_dir=os.path.join('logs'))])\n",
    "\n",
    "# Save the model\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "126d82ac-2102-4dc5-b81a-5a80681f5ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step\n",
      "0.8115942028985508\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "print(accuracy_score(ytrue, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d5b07735-16ef-4645-aefb-90af6eefd115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 46), dtype=float32, sparse=False, name=keras_tensor_294>]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5b24b162-ed7d-4c85-a7a4-497c6693867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DHO_d\\AppData\\Local\\Temp\\tmpcv0gr00x\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\DHO_d\\AppData\\Local\\Temp\\tmpcv0gr00x\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\DHO_d\\AppData\\Local\\Temp\\tmpcv0gr00x'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30, 42), dtype=tf.float32, name='input_layer_5')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 46), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2288395112464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288395119376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417216784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417222736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417215056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417216208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417217552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417217360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417221008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417218896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417216592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417219088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417212368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417220624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2288417212752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "# Load the Keras model from the .h5 file\n",
    "model = tf.keras.models.load_model(\"final_model.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Enable TF Select ops\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Use TensorFlow Lite's built-in ops\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # Use TensorFlow ops for unsupported ops\n",
    "]\n",
    "\n",
    "# Disable lowering tensor list ops\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open(\"lstm_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3406ef90-e93a-43b1-aa4e-151f05dba5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"lstm_model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5f27af99-5351-43e7-ad4e-ce838319fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input_layer_5:0', 'index': 0, 'shape': array([ 1, 30, 42]), 'shape_signature': array([-1, 30, 42]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 64, 'shape': array([ 1, 46]), 'shape_signature': array([-1, 46]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Allocate tensors\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Print input and output details to check shapes and types\n",
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7b0388d2-0df6-41d5-be1f-c49b17ebb1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to run inference on a single input\n",
    "def predict_tflite(interpreter, input_data):\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return output\n",
    "\n",
    "# Assuming X_test and y_test are your test dataset and labels\n",
    "# If y_test is one-hot encoded, convert it to class indices\n",
    "if len(y_test.shape) > 1:  # Check if y_test is one-hot encoded\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Running inference and getting predictions\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    input_data = np.float32(np.expand_dims(X_test[i], axis=0))  # Add batch dimension\n",
    "    prediction = predict_tflite(interpreter, input_data)\n",
    "    y_pred.append(np.argmax(prediction, axis=1)[0])  # Get the predicted class\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
